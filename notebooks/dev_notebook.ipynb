{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Example in how to use ChatModel Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatModel(sync_client=<openai.OpenAI object at 0x11f389690>, async_client=<openai.AsyncOpenAI object at 0x11f3aca50>, model='gpt-3.5-turbo-1106', temperature=0.9, top_p=0.9, max_tokens=None, n=1, seed=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from automated_llm_eval.chat_model import ChatModel, Message\n",
    "from automated_llm_eval.utils import ProgressBar\n",
    "\n",
    "# Instantiate wrapper around OpenAI's API\n",
    "model = ChatModel(model=\"gpt-3.5-turbo-1106\")\n",
    "# model = ChatModel(model=\"gpt-4-1106-preview\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatModel(sync_client=<openai.OpenAI object at 0x11f389690>, async_client=<openai.AsyncOpenAI object at 0x11f3aca50>, model='gpt-3.5-turbo-1106', temperature=0.5, top_p=0.5, max_tokens=300, n=1, seed=42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can adjust other model settings globally for all API calls\n",
    "model2 = ChatModel(model=\"gpt-3.5-turbo-1106\", temperature=0.5, top_p=0.5, max_tokens=300, seed=42)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatModel(sync_client=<openai.OpenAI object at 0x11f389690>, async_client=<openai.AsyncOpenAI object at 0x11f3aca50>, model='gpt-3.5-turbo-1106', temperature=0.5, top_p=0.5, max_tokens=None, n=1, seed=42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `max_tokens = None` means no max_token limit (this is the default)\n",
    "model2 = ChatModel(model=\"gpt-3.5-turbo-1106\", temperature=0.5, top_p=0.5, max_tokens=None, seed=42)\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Making API calls using synchronous (blocking) client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the apple break up with the banana? \n",
      "Because it couldn't find a core connection!\n"
     ]
    }
   ],
   "source": [
    "# Make API call, get response message.\n",
    "# Note: `output_format = \"simple\"`\n",
    "response_message = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=\"simple\",\n",
    ")\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8L3W9TIldkm9lp5Id5smuRHgN0w9e', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"Why did the apple go to the doctor? Because it wasn't peeling well!\", role='assistant', function_call=None, tool_calls=None))], created=1700029101, model='gpt-3.5-turbo-1106', object='chat.completion', system_fingerprint='fp_eeff13170a', usage=CompletionUsage(completion_tokens=17, prompt_tokens=24, total_tokens=41))\n"
     ]
    }
   ],
   "source": [
    "# Make API call, get original ChatCompletion object.\n",
    "# Note: `output_format = None`\n",
    "response = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=None,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MessageBundle(id='chatcmpl-8L3WAFh0fxiMJi3jVhpOkctDBV7ZT', system_message='You are a joke telling machine.', user_message='Tell me something about apples.', response_message=\"Why did the apple go to the doctor? Because it wasn't peeling well!\", created_time=1700029102, model='gpt-3.5-turbo-1106', total_tokens=41, prompt_tokens=24, completion_tokens=17, seed=None, temperature=0.9, top_p=0.9, max_tokens=None)\n"
     ]
    }
   ],
   "source": [
    "# Make API call, get response packaged with input + metadata.\n",
    "# Note: `output_format = \"message_bundle\"`\n",
    "message_bundle = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=\"message_bundle\",\n",
    ")\n",
    "print(message_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8L3WByxod4QVo6QmhwaTTkwj36SPL', 'system_message': 'You are a joke telling machine.', 'user_message': 'Tell me something about apples.', 'response_message': \"Why did the apple go to the doctor? Because it wasn't peeling well!\", 'created_time': 1700029103, 'model': 'gpt-3.5-turbo-1106', 'total_tokens': 41, 'prompt_tokens': 24, 'completion_tokens': 17, 'seed': None, 'temperature': 0.9, 'top_p': 0.9, 'max_tokens': None}\n"
     ]
    }
   ],
   "source": [
    "# Make API call, get MessageBundle as a dict.\n",
    "# Note: `output_format = \"message_bundle_dict\"`\n",
    "message_bundle_dict = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=\"message_bundle_dict\",\n",
    ")\n",
    "print(message_bundle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              chatcmpl-8L3WByxod4QVo6QmhwaTTkwj36SPL\n",
       "system_message                         You are a joke telling machine.\n",
       "user_message                           Tell me something about apples.\n",
       "response_message     Why did the apple go to the doctor? Because it...\n",
       "created_time                                                1700029103\n",
       "model                                               gpt-3.5-turbo-1106\n",
       "total_tokens                                                        41\n",
       "prompt_tokens                                                       24\n",
       "completion_tokens                                                   17\n",
       "seed                                                              None\n",
       "temperature                                                        0.9\n",
       "top_p                                                              0.9\n",
       "max_tokens                                                        None\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Message bundle dict can be converted into pandas Series easily\n",
    "s = pd.Series(message_bundle_dict)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e090bf873a5e445790af788d1f50a563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>system_message</th>\n",
       "      <th>user_message</th>\n",
       "      <th>response_message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>model</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>seed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>max_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatcmpl-8L3WCfvuieczCx930XRR6nf4oAp6L</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Sure! Did you hear about the apple who went to...</td>\n",
       "      <td>1700029104</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>57</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatcmpl-8L3WD817kxZs2YBA9iE21oyN0Qy7N</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to therapy? Because it ha...</td>\n",
       "      <td>1700029105</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatcmpl-8L3WESOE8EPLVXy2da9RIYwD4Ly7i</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to therapy? Because it ha...</td>\n",
       "      <td>1700029106</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatcmpl-8L3WEUWxZNWxIDQH7csenDj9RPypv</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1700029106</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatcmpl-8L3WHFT97y0VMqI5WS2XVkXnVRtb4</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1700029109</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id                   system_message  \\\n",
       "0  chatcmpl-8L3WCfvuieczCx930XRR6nf4oAp6L  You are a joke telling machine.   \n",
       "1  chatcmpl-8L3WD817kxZs2YBA9iE21oyN0Qy7N  You are a joke telling machine.   \n",
       "2  chatcmpl-8L3WESOE8EPLVXy2da9RIYwD4Ly7i  You are a joke telling machine.   \n",
       "3  chatcmpl-8L3WEUWxZNWxIDQH7csenDj9RPypv  You are a joke telling machine.   \n",
       "4  chatcmpl-8L3WHFT97y0VMqI5WS2XVkXnVRtb4  You are a joke telling machine.   \n",
       "\n",
       "                      user_message  \\\n",
       "0  Tell me something about apples.   \n",
       "1  Tell me something about apples.   \n",
       "2  Tell me something about apples.   \n",
       "3  Tell me something about apples.   \n",
       "4  Tell me something about apples.   \n",
       "\n",
       "                                    response_message  created_time  \\\n",
       "0  Sure! Did you hear about the apple who went to...    1700029104   \n",
       "1  Why did the apple go to therapy? Because it ha...    1700029105   \n",
       "2  Why did the apple go to therapy? Because it ha...    1700029106   \n",
       "3  Why did the apple go to the doctor? Because it...    1700029106   \n",
       "4  Why did the apple go to the doctor? Because it...    1700029109   \n",
       "\n",
       "                model  total_tokens  prompt_tokens  completion_tokens  seed  \\\n",
       "0  gpt-3.5-turbo-1106            57             24                 33  None   \n",
       "1  gpt-3.5-turbo-1106            40             24                 16  None   \n",
       "2  gpt-3.5-turbo-1106            40             24                 16  None   \n",
       "3  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "4  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "\n",
       "   temperature  top_p max_tokens  \n",
       "0          0.4    0.9       None  \n",
       "1          0.4    0.9       None  \n",
       "2          0.4    0.9       None  \n",
       "3          0.4    0.9       None  \n",
       "4          0.4    0.9       None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple message bundle dicts can be converted into pandas DataFrame\n",
    "# NOTE: if an API call fails, then `None` will be returned. `None` items cannot\n",
    "# be directly converted into pd.DataFrame\n",
    "responses = []\n",
    "with ProgressBar() as p:\n",
    "    for _ in p.track(range(5)):\n",
    "        response = model.create_chat_completion(\n",
    "            system_message=\"You are a joke telling machine.\",\n",
    "            user_message=\"Tell me something about apples.\",\n",
    "            output_format=\"message_bundle_dict\",\n",
    "            temperature=0.4,\n",
    "            seed=None,\n",
    "        )\n",
    "        responses += [response]\n",
    "\n",
    "df = pd.DataFrame(responses)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8L3WINIS7OgDe8wlZ2avZQqaadGh6', 'system_message': 'You are a joke telling machine.', 'user_message': 'Tell me something about apples.', 'response_message': \"Why did the apple go to the doctor? Because it wasn't peeling well!\", 'created_time': 1700029110, 'model': 'gpt-3.5-turbo-1106', 'total_tokens': 41, 'prompt_tokens': 24, 'completion_tokens': 17, 'seed': None, 'temperature': 0.9, 'top_p': 0.9, 'max_tokens': None}\n"
     ]
    }
   ],
   "source": [
    "# If an API call fails, this method will automatically retry and make another API call.\n",
    "# By default it will retry 5 times.  We can change this value to 2.\n",
    "message_bundle_dict = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=\"message_bundle_dict\",\n",
    "    num_retries=2,\n",
    ")\n",
    "print(message_bundle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8L3WOZPK1FLUwmRFPlkDkWjsRV5YT', 'system_message': 'You are a joke telling machine.', 'user_message': 'Tell me something about apples.', 'response_message': 'Why did the apple go to therapy? Because it had too many core issues!', 'created_time': 1700029116, 'model': 'gpt-3.5-turbo-1106', 'total_tokens': 40, 'prompt_tokens': 24, 'completion_tokens': 16, 'seed': None, 'temperature': 0.9, 'top_p': 0.9, 'max_tokens': None}\n"
     ]
    }
   ],
   "source": [
    "# The `create_chat_completion` method is syntactic sugar for `chat_completion`.\n",
    "# It simply formats the message for us.\n",
    "system_message = \"You are a joke telling machine.\"\n",
    "user_message = \"Tell me something about apples.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "\n",
    "message_bundle_dict = model.chat_completion(\n",
    "    messages=messages,\n",
    "    output_format=\"message_bundle_dict\",\n",
    "    num_retries=2,\n",
    ")\n",
    "print(message_bundle_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Making API calls using asynchronous (non-blocking) client\n",
    "\n",
    " This enables concurrent API calls.  We can control the max concurrency.\n",
    "\n",
    " Async uses the asyncio paradigm.  We need to run an asyncio event loop to\n",
    " use these functions.\n",
    " NOTE: a jupyter notebook has an asyncio event loop running by default,\n",
    " but you need to create your own asyncio event loop in a python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8L3WPSEyFwDZa6QxecK3yn00RcNRI', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Sure! Did you hear about the apple who went to the doctor? It wasn\\'t feeling well, but the doctor said, \"Don\\'t worry, you just need to stop hanging out with bad seeds!\"', role='assistant', function_call=None, tool_calls=None))], created=1700029117, model='gpt-3.5-turbo-1106', object='chat.completion', system_fingerprint='fp_eeff13170a', usage=CompletionUsage(completion_tokens=41, prompt_tokens=24, total_tokens=65))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a joke telling machine.\"\n",
    "user_message = \"Tell me something about apples.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "\n",
    "response = await model.async_chat_completion(messages=messages, num_retries=1)  # noqa: F704:\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate Messages x 5 times so that we can make 5 API calls\n",
    "messages_list = [messages] * 5\n",
    "messages_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c82e746be34b77bf860677a2d21a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>system_message</th>\n",
       "      <th>user_message</th>\n",
       "      <th>response_message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>model</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>seed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>max_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatcmpl-8L3WQBtmZrNvRNksvFTlmx8KNNi4H</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Sure! Did you hear about the apple who went to...</td>\n",
       "      <td>1700029118</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatcmpl-8L3WQSMF8GINMZIVILStFjkEuL0uh</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to therapy?\\nBecause it h...</td>\n",
       "      <td>1700029118</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatcmpl-8L3WRp8Ypiq37govF5g9VOKODd9fa</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to school?\\n\\nBecause it ...</td>\n",
       "      <td>1700029119</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatcmpl-8L3WSVlnUVFaAXyrALJP3Xemd0ib7</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1700029120</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatcmpl-8L3WS8AOOit8pLrxtxoIiIKFGbzzI</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple stop in the middle of the ro...</td>\n",
       "      <td>1700029120</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id                   system_message  \\\n",
       "0  chatcmpl-8L3WQBtmZrNvRNksvFTlmx8KNNi4H  You are a joke telling machine.   \n",
       "1  chatcmpl-8L3WQSMF8GINMZIVILStFjkEuL0uh  You are a joke telling machine.   \n",
       "2  chatcmpl-8L3WRp8Ypiq37govF5g9VOKODd9fa  You are a joke telling machine.   \n",
       "3  chatcmpl-8L3WSVlnUVFaAXyrALJP3Xemd0ib7  You are a joke telling machine.   \n",
       "4  chatcmpl-8L3WS8AOOit8pLrxtxoIiIKFGbzzI  You are a joke telling machine.   \n",
       "\n",
       "                      user_message  \\\n",
       "0  Tell me something about apples.   \n",
       "1  Tell me something about apples.   \n",
       "2  Tell me something about apples.   \n",
       "3  Tell me something about apples.   \n",
       "4  Tell me something about apples.   \n",
       "\n",
       "                                    response_message  created_time  \\\n",
       "0  Sure! Did you hear about the apple who went to...    1700029118   \n",
       "1  Why did the apple go to therapy?\\nBecause it h...    1700029118   \n",
       "2  Why did the apple go to school?\\n\\nBecause it ...    1700029119   \n",
       "3  Why did the apple go to the doctor? Because it...    1700029120   \n",
       "4  Why did the apple stop in the middle of the ro...    1700029120   \n",
       "\n",
       "                model  total_tokens  prompt_tokens  completion_tokens  seed  \\\n",
       "0  gpt-3.5-turbo-1106            50             24                 26  None   \n",
       "1  gpt-3.5-turbo-1106            40             24                 16  None   \n",
       "2  gpt-3.5-turbo-1106            43             24                 19  None   \n",
       "3  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "4  gpt-3.5-turbo-1106            43             24                 19  None   \n",
       "\n",
       "   temperature  top_p max_tokens  \n",
       "0          0.9    0.9       None  \n",
       "1          0.9    0.9       None  \n",
       "2          0.9    0.9       None  \n",
       "3          0.9    0.9       None  \n",
       "4          0.9    0.9       None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Async Chat Completions, limit to 2 concurrent API calls at any given time\n",
    "responses_list = await model.async_chat_completions(  # noqa: F704\n",
    "    messages_list=messages_list,\n",
    "    num_concurrent=2,\n",
    "    num_retries=1,\n",
    "    output_format=\"message_bundle_dict\",\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(responses_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Example of using `Message` and `validation_callback`\n",
    "\n",
    " The `Message` wrapper allows packaging arbitrary user-defined metadata along with each message\n",
    " which is a good place to put labels, notes, etc.\n",
    "\n",
    " The `validation_callback` argument enables the user to define\n",
    " specific logic to validate the response from each API call to OpenAI\n",
    " for each message.  Passed into the callback function is the original\n",
    " `messages` and the `response`.  If the `messages` is a `Message` object,\n",
    " this will be returned in `validation_callback` for access to all metadata.\n",
    " `response` is the LLM response after being parsed and formated as specified\n",
    " in `output_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Callback. Messages: Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role': 'user', 'content': 'Tell me something about apples.'}], metadata={'a': 1})\n",
      "In Callback. Response: Why did the apple go to therapy? Because it had too many cores issues!\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Why did the apple go to therapy? Because it had too many cores issues!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a joke telling machine.\"\n",
    "user_message = \"Tell me something about apples.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "m = Message(messages=messages, metadata={\"a\": 1})\n",
    "\n",
    "\n",
    "def validation_callback_fn(messages, response) -> bool:\n",
    "    print(f\"In Callback. Messages: {messages}\")\n",
    "    print(f\"In Callback. Response: {response}\")\n",
    "    print(\"\\n\")\n",
    "    metadata = messages.metadata\n",
    "    if \"a\" in metadata:\n",
    "        return metadata[\"a\"] == 1\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Instantiate wrapper around OpenAI's API\n",
    "model = ChatModel(model=\"gpt-3.5-turbo-1106\")\n",
    "# Make ChatCompletion with...\n",
    "# - using Message wrapper and include metadata (ChatModel automatically unpacks Message.messages)\n",
    "# - parse raw OpenAI response into \"simple\" string format\n",
    "# - then call the `validation_callback_fn` that we defined.  ChatModel always passes in\n",
    "#   original messages input and parsed response as the 1st and 2nd arguments.  The\n",
    "#   `validation_callback_fn` can contain any logic, but ultimately needs to return `True` vs `False`\n",
    "#   to accept or reject the response.  If the response is rejected, ChatModel automatically retries.\n",
    "# - allow up to 1 retry.  If still fails/rejected after 1 retry, then will return `None`.\n",
    "response = model.chat_completion(\n",
    "    m,\n",
    "    output_format=\"simple\",\n",
    "    validation_callback=validation_callback_fn,\n",
    "    num_retries=1,\n",
    ")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role': 'user', 'content': 'Tell me something about apples.'}], metadata={'a': 1}),\n",
       " Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role': 'user', 'content': 'Tell me something about apples.'}], metadata={'a': 1}),\n",
       " Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role': 'user', 'content': 'Tell me something about apples.'}], metadata={'b': 2})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple concurrent async chat completions using Message\n",
    "# NOTE: we make the 3rd Message with different metadata.  This should cause\n",
    "# the `validation_callback_fn` to reject the response for only the 3rd Message in list\n",
    "# and retry only the 3rd Message.\n",
    "m_list = [m] * 2 + [Message(messages=messages, metadata={\"b\": 2})]\n",
    "m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65f1026874c433bb8d845ab145cdb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In Callback. Messages: Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role':\n",
       "'user', 'content': 'Tell me something about apples.'}], metadata={'a': 1})\n",
       "</pre>\n"
      ],
      "text/plain": [
       "In Callback. Messages: Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role':\n",
       "'user', 'content': 'Tell me something about apples.'}], metadata={'a': 1})\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In Callback. Response: Why did the apple go to the doctor? Because it wasn't peeling well!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "In Callback. Response: Why did the apple go to the doctor? Because it wasn't peeling well!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In Callback. Messages: Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role':\n",
       "'user', 'content': 'Tell me something about apples.'}], metadata={'a': 1})\n",
       "</pre>\n"
      ],
      "text/plain": [
       "In Callback. Messages: Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role':\n",
       "'user', 'content': 'Tell me something about apples.'}], metadata={'a': 1})\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In Callback. Response: Sure! Did you hear about the apple that went to a party? It was a-peeling!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "In Callback. Response: Sure! Did you hear about the apple that went to a party? It was a-peeling!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In Callback. Messages: Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role':\n",
       "'user', 'content': 'Tell me something about apples.'}], metadata={'b': 2})\n",
       "</pre>\n"
      ],
      "text/plain": [
       "In Callback. Messages: Message(messages=[{'role': 'system', 'content': 'You are a joke telling machine.'}, {'role':\n",
       "'user', 'content': 'Tell me something about apples.'}], metadata={'b': 2})\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Because it wasn't peeling well!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Because it wasn't peeling well!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">In Callback. Response: Sure, here's a joke about apples:\n",
       "\n",
       "Why did the apple go to the doctor?\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "/Users/philipchung/Developer/automated-llm-eval/automated_llm_eval/chat_model.py:308: UserWarning: Failed to create\n",
       "ChatCompletion with arguments: dict_items([('messages', Message(messages=[{'role': 'system', 'content': 'You are a \n",
       "joke telling machine.'}, {'role': 'user', 'content': 'Tell me something about apples.'}], metadata={'b': 2})), \n",
       "('model', 'gpt-3.5-turbo-1106'), ('temperature', 0.9), ('top_p', 0.9), ('max_tokens', None), ('n', 1), ('seed', \n",
       "None)])\n",
       "Exception: maximum recursion depth exceeded\n",
       "Retries left: 1\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "In Callback. Response: Sure, here's a joke about apples:\n",
       "\n",
       "Why did the apple go to the doctor?\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "Because it wasn't peeling well!\n",
       "/Users/philipchung/Developer/automated-llm-eval/automated_llm_eval/chat_model.py:308: UserWarning: Failed to create\n",
       "ChatCompletion with arguments: dict_items([('messages', Message(messages=[{'role': 'system', 'content': 'You are a \n",
       "joke telling machine.'}, {'role': 'user', 'content': 'Tell me something about apples.'}], metadata={'b': 2})), \n",
       "('model', 'gpt-3.5-turbo-1106'), ('temperature', 0.9), ('top_p', 0.9), ('max_tokens', None), ('n', 1), ('seed', \n",
       "None)])\n",
       "Exception: maximum recursion depth exceeded\n",
       "Retries left: 1\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Async Chat Completions, limit to 2 concurrent API calls at any given time & 1 retry\n",
    "responses_list = await model.async_chat_completions(  # noqa: F704\n",
    "    messages_list=m_list,\n",
    "    num_concurrent=2,\n",
    "    num_retries=1,\n",
    "    validation_callback=validation_callback_fn,\n",
    "    output_format=\"simple\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sure! Did you hear about the apple that went to a party? It was a-peeling!',\n",
       " \"Why did the apple go to the doctor? Because it wasn't peeling well!\",\n",
       " None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine responses.\n",
    "# - We should get valid responses for the first 2 responses.\n",
    "# - The 3rd response should always be `None` because the metadata cannot pass at\n",
    "#   `validation_callback_fn`\n",
    "responses_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated-llm-eval-BWtWBPiB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
