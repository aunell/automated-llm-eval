{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Example in how to use ChatModel Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatModel(sync_client=<openai.OpenAI object at 0x11f9bcbd0>, async_client=<openai.AsyncOpenAI object at 0x11f9e0390>, model='gpt-3.5-turbo-1106', temperature=0.9, top_p=0.9, max_tokens=None, n=1, seed=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from automated_llm_eval.chat_model import ChatModel\n",
    "from automated_llm_eval.utils import ProgressBar\n",
    "\n",
    "# Instantiate wrapper around OpenAI's API\n",
    "model = ChatModel(model=\"gpt-3.5-turbo-1106\")\n",
    "# model = ChatModel(model=\"gpt-4-1106-preview\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatModel(sync_client=<openai.OpenAI object at 0x11f9bcbd0>, async_client=<openai.AsyncOpenAI object at 0x11f9e0390>, model='gpt-3.5-turbo-1106', temperature=0.5, top_p=0.5, max_tokens=300, n=1, seed=42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can adjust other model settings globally for all API calls\n",
    "model2 = ChatModel(model=\"gpt-3.5-turbo-1106\", temperature=0.5, top_p=0.5, max_tokens=300, seed=42)\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Making API calls using synchronous (blocking) client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the apple break up with the banana? \n",
      "Because it couldn't find a core connection!\n"
     ]
    }
   ],
   "source": [
    "# Make API call, get response message.\n",
    "# Note: `output_format = \"simple\"`\n",
    "response_message = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=\"simple\",\n",
    ")\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8JFF2SxR101cQNYFQyvrsqYyUSnK7', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Sure! Did you know that apples are great at socializing? They\\'re always getting invited to \"core\" parties!', role='assistant', function_call=None, tool_calls=None))], created=1699597512, model='gpt-3.5-turbo-1106', object='chat.completion', system_fingerprint='fp_eeff13170a', usage=CompletionUsage(completion_tokens=24, prompt_tokens=24, total_tokens=48))\n"
     ]
    }
   ],
   "source": [
    "# Make API call, get original ChatCompletion object.\n",
    "# Note: `output_format = None`\n",
    "response = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=None,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MessageBundle(id='chatcmpl-8JFF46SDdfvuNptYp4asGNgRPdl52', system_message='You are a joke telling machine.', user_message='Tell me something about apples.', response_message='Why did the apple go to therapy? Because it had too many core issues!', created_time=1699597514, model='gpt-3.5-turbo-1106', total_tokens=40, prompt_tokens=24, completion_tokens=16, seed=None, temperature=0.9, top_p=0.9, max_tokens=None)\n"
     ]
    }
   ],
   "source": [
    "# Make API call, get response packaged with input + metadata.\n",
    "# Note: `output_format = \"message_bundle\"`\n",
    "message_bundle = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=\"message_bundle\",\n",
    ")\n",
    "print(message_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8JFF63WKzk4sdG70iX0evwBr1dUaf', 'system_message': 'You are a joke telling machine.', 'user_message': 'Tell me something about apples.', 'response_message': 'Why did the apple go to school? Because it wanted to be a little bit more well-rounded!', 'created_time': 1699597516, 'model': 'gpt-3.5-turbo-1106', 'total_tokens': 44, 'prompt_tokens': 24, 'completion_tokens': 20, 'seed': None, 'temperature': 0.9, 'top_p': 0.9, 'max_tokens': None}\n"
     ]
    }
   ],
   "source": [
    "# Make API call, get MessageBundle as a dict.\n",
    "# Note: `output_format = \"message_bundle_dict\"`\n",
    "message_bundle_dict = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=\"message_bundle_dict\",\n",
    ")\n",
    "print(message_bundle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              chatcmpl-8JFF63WKzk4sdG70iX0evwBr1dUaf\n",
       "system_message                         You are a joke telling machine.\n",
       "user_message                           Tell me something about apples.\n",
       "response_message     Why did the apple go to school? Because it wan...\n",
       "created_time                                                1699597516\n",
       "model                                               gpt-3.5-turbo-1106\n",
       "total_tokens                                                        44\n",
       "prompt_tokens                                                       24\n",
       "completion_tokens                                                   20\n",
       "seed                                                              None\n",
       "temperature                                                        0.9\n",
       "top_p                                                              0.9\n",
       "max_tokens                                                        None\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Message bundle dict can be converted into pandas Series easily\n",
    "s = pd.Series(message_bundle_dict)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8adfa16f03448b84ea4a0044c58609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>system_message</th>\n",
       "      <th>user_message</th>\n",
       "      <th>response_message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>model</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>seed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>max_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatcmpl-8JFF7mm14Wn2KZKyriFmBKIr9cjGz</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1699597517</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatcmpl-8JFF7WOtyhpaDyXAwI4IgrrHdWfqN</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1699597517</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatcmpl-8JFF9heQXGGzkLtJ8wJap4WxTJt38</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Sure! Did you hear about the apple who went to...</td>\n",
       "      <td>1699597519</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatcmpl-8JFFB9vbg1owUUK9BlF4tR5ghvP3Z</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1699597521</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatcmpl-8JFFCCectMkEIEDjqxYM3KwoAVa34</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1699597522</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id                   system_message  \\\n",
       "0  chatcmpl-8JFF7mm14Wn2KZKyriFmBKIr9cjGz  You are a joke telling machine.   \n",
       "1  chatcmpl-8JFF7WOtyhpaDyXAwI4IgrrHdWfqN  You are a joke telling machine.   \n",
       "2  chatcmpl-8JFF9heQXGGzkLtJ8wJap4WxTJt38  You are a joke telling machine.   \n",
       "3  chatcmpl-8JFFB9vbg1owUUK9BlF4tR5ghvP3Z  You are a joke telling machine.   \n",
       "4  chatcmpl-8JFFCCectMkEIEDjqxYM3KwoAVa34  You are a joke telling machine.   \n",
       "\n",
       "                      user_message  \\\n",
       "0  Tell me something about apples.   \n",
       "1  Tell me something about apples.   \n",
       "2  Tell me something about apples.   \n",
       "3  Tell me something about apples.   \n",
       "4  Tell me something about apples.   \n",
       "\n",
       "                                    response_message  created_time  \\\n",
       "0  Why did the apple go to the doctor? Because it...    1699597517   \n",
       "1  Why did the apple go to the doctor? Because it...    1699597517   \n",
       "2  Sure! Did you hear about the apple who went to...    1699597519   \n",
       "3  Why did the apple go to the doctor? Because it...    1699597521   \n",
       "4  Why did the apple go to the doctor? Because it...    1699597522   \n",
       "\n",
       "                model  total_tokens  prompt_tokens  completion_tokens  seed  \\\n",
       "0  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "1  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "2  gpt-3.5-turbo-1106            60             24                 36  None   \n",
       "3  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "4  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "\n",
       "   temperature  top_p max_tokens  \n",
       "0          0.4    0.9       None  \n",
       "1          0.4    0.9       None  \n",
       "2          0.4    0.9       None  \n",
       "3          0.4    0.9       None  \n",
       "4          0.4    0.9       None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple message bundle dicts can be converted into pandas DataFrame\n",
    "# NOTE: if an API call fails, then `None` will be returned. `None` items cannot\n",
    "# be directly converted into pd.DataFrame\n",
    "responses = []\n",
    "with ProgressBar() as p:\n",
    "    for _ in p.track(range(5)):\n",
    "        response = model.create_chat_completion(\n",
    "            system_message=\"You are a joke telling machine.\",\n",
    "            user_message=\"Tell me something about apples.\",\n",
    "            output_format=\"message_bundle_dict\",\n",
    "            temperature=0.4,\n",
    "            seed=None,\n",
    "        )\n",
    "        responses += [response]\n",
    "\n",
    "df = pd.DataFrame(responses)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8JFFDzbuR6nS9szV0jiU9RgU2tAhW', 'system_message': 'You are a joke telling machine.', 'user_message': 'Tell me something about apples.', 'response_message': \"Why did the apple go to the doctor?\\n\\nBecause it wasn't peeling well!\", 'created_time': 1699597523, 'model': 'gpt-3.5-turbo-1106', 'total_tokens': 41, 'prompt_tokens': 24, 'completion_tokens': 17, 'seed': None, 'temperature': 0.9, 'top_p': 0.9, 'max_tokens': None}\n"
     ]
    }
   ],
   "source": [
    "# If an API call fails, this method will automatically retry and make another API call.\n",
    "# By default it will retry 5 times.  We can change this value to 2.\n",
    "message_bundle_dict = model.create_chat_completion(\n",
    "    system_message=\"You are a joke telling machine.\",\n",
    "    user_message=\"Tell me something about apples.\",\n",
    "    output_format=\"message_bundle_dict\",\n",
    "    num_retries=2,\n",
    ")\n",
    "print(message_bundle_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8JFFDfCbOQYwVeHOJYejsx5ZxiLIz', 'system_message': 'You are a joke telling machine.', 'user_message': 'Tell me something about apples.', 'response_message': 'Sure! Did you hear about the apple who got into a fight? It was bruised!', 'created_time': 1699597523, 'model': 'gpt-3.5-turbo-1106', 'total_tokens': 43, 'prompt_tokens': 24, 'completion_tokens': 19, 'seed': None, 'temperature': 0.9, 'top_p': 0.9, 'max_tokens': None}\n"
     ]
    }
   ],
   "source": [
    "# The `create_chat_completion` method is syntactic sugar for `chat_completion`.\n",
    "# It simply formats the message for us.\n",
    "system_message = \"You are a joke telling machine.\"\n",
    "user_message = \"Tell me something about apples.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "\n",
    "message_bundle_dict = model.chat_completion(\n",
    "    messages=messages,\n",
    "    output_format=\"message_bundle_dict\",\n",
    "    num_retries=2,\n",
    ")\n",
    "print(message_bundle_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Making API calls using asynchronous (non-blocking) client\n",
    "\n",
    " This enables concurrent API calls.  We can control the max concurrency.\n",
    "\n",
    " Async uses the asyncio paradigm.  We need to run an asyncio event loop to\n",
    " use these functions.\n",
    " NOTE: a jupyter notebook has an asyncio event loop running by default,\n",
    " but you need to create your own asyncio event loop in a python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8JFFEHjBtLwtcBlYmBkCHMA1qNjdy', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"Why did the apple go to the doctor? Because it wasn't peeling well!\", role='assistant', function_call=None, tool_calls=None))], created=1699597524, model='gpt-3.5-turbo-1106', object='chat.completion', system_fingerprint='fp_eeff13170a', usage=CompletionUsage(completion_tokens=17, prompt_tokens=24, total_tokens=41))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a joke telling machine.\"\n",
    "user_message = \"Tell me something about apples.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "\n",
    "response = await model.async_chat_completion(messages=messages)  # noqa: F704:\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}],\n",
       " [{'role': 'system', 'content': 'You are a joke telling machine.'},\n",
       "  {'role': 'user', 'content': 'Tell me something about apples.'}]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate Messages x 10 times so that we can make 10 API calls\n",
    "messages_list = [messages] * 10\n",
    "messages_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb8b4fc226f41548a881a782c57d7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>system_message</th>\n",
       "      <th>user_message</th>\n",
       "      <th>response_message</th>\n",
       "      <th>created_time</th>\n",
       "      <th>model</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>seed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>max_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatcmpl-8JFFFNCTfjm6VS1zIq9cQCTydKQeK</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple break up with the orange? Be...</td>\n",
       "      <td>1699597525</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatcmpl-8JFFHT8BIr6EqjaVr39ZlEtr7PtoB</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1699597527</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatcmpl-8JFFGPzV6Ol9LlPBTA8Gww2Dk3Jw2</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Sure! Did you know that apples are actually a ...</td>\n",
       "      <td>1699597526</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>68</td>\n",
       "      <td>24</td>\n",
       "      <td>44</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatcmpl-8JFFHy8V0Cc3uqSNLmxqGK995wiQS</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to therapy?\\n\\nBecause it...</td>\n",
       "      <td>1699597527</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatcmpl-8JFFIMVSkvlhSUGExSNJdue5tbSE7</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to therapy? Because it ha...</td>\n",
       "      <td>1699597528</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chatcmpl-8JFFJYlNCrbqKU3jxrCNcPYgs0WeG</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor?\\n\\nBecause...</td>\n",
       "      <td>1699597529</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chatcmpl-8JFFJj4ydNqdL5z8d0DPOlC8I6jt8</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Sure! Did you hear about the apple who joined ...</td>\n",
       "      <td>1699597529</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>47</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chatcmpl-8JFFKc1impJk3MPV84d2oQXHIQnDk</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1699597530</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chatcmpl-8JFFKcoCma8u0rjMybygfwh4gVnmL</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1699597530</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chatcmpl-8JFFKHgZsib76yJJzWoPrLKP3hS95</td>\n",
       "      <td>You are a joke telling machine.</td>\n",
       "      <td>Tell me something about apples.</td>\n",
       "      <td>Why did the apple go to the doctor? Because it...</td>\n",
       "      <td>1699597530</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id                   system_message  \\\n",
       "0  chatcmpl-8JFFFNCTfjm6VS1zIq9cQCTydKQeK  You are a joke telling machine.   \n",
       "1  chatcmpl-8JFFHT8BIr6EqjaVr39ZlEtr7PtoB  You are a joke telling machine.   \n",
       "2  chatcmpl-8JFFGPzV6Ol9LlPBTA8Gww2Dk3Jw2  You are a joke telling machine.   \n",
       "3  chatcmpl-8JFFHy8V0Cc3uqSNLmxqGK995wiQS  You are a joke telling machine.   \n",
       "4  chatcmpl-8JFFIMVSkvlhSUGExSNJdue5tbSE7  You are a joke telling machine.   \n",
       "5  chatcmpl-8JFFJYlNCrbqKU3jxrCNcPYgs0WeG  You are a joke telling machine.   \n",
       "6  chatcmpl-8JFFJj4ydNqdL5z8d0DPOlC8I6jt8  You are a joke telling machine.   \n",
       "7  chatcmpl-8JFFKc1impJk3MPV84d2oQXHIQnDk  You are a joke telling machine.   \n",
       "8  chatcmpl-8JFFKcoCma8u0rjMybygfwh4gVnmL  You are a joke telling machine.   \n",
       "9  chatcmpl-8JFFKHgZsib76yJJzWoPrLKP3hS95  You are a joke telling machine.   \n",
       "\n",
       "                      user_message  \\\n",
       "0  Tell me something about apples.   \n",
       "1  Tell me something about apples.   \n",
       "2  Tell me something about apples.   \n",
       "3  Tell me something about apples.   \n",
       "4  Tell me something about apples.   \n",
       "5  Tell me something about apples.   \n",
       "6  Tell me something about apples.   \n",
       "7  Tell me something about apples.   \n",
       "8  Tell me something about apples.   \n",
       "9  Tell me something about apples.   \n",
       "\n",
       "                                    response_message  created_time  \\\n",
       "0  Why did the apple break up with the orange? Be...    1699597525   \n",
       "1  Why did the apple go to the doctor? Because it...    1699597527   \n",
       "2  Sure! Did you know that apples are actually a ...    1699597526   \n",
       "3  Why did the apple go to therapy?\\n\\nBecause it...    1699597527   \n",
       "4  Why did the apple go to therapy? Because it ha...    1699597528   \n",
       "5  Why did the apple go to the doctor?\\n\\nBecause...    1699597529   \n",
       "6  Sure! Did you hear about the apple who joined ...    1699597529   \n",
       "7  Why did the apple go to the doctor? Because it...    1699597530   \n",
       "8  Why did the apple go to the doctor? Because it...    1699597530   \n",
       "9  Why did the apple go to the doctor? Because it...    1699597530   \n",
       "\n",
       "                model  total_tokens  prompt_tokens  completion_tokens  seed  \\\n",
       "0  gpt-3.5-turbo-1106            43             24                 19  None   \n",
       "1  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "2  gpt-3.5-turbo-1106            68             24                 44  None   \n",
       "3  gpt-3.5-turbo-1106            42             24                 18  None   \n",
       "4  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "5  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "6  gpt-3.5-turbo-1106            47             24                 23  None   \n",
       "7  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "8  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "9  gpt-3.5-turbo-1106            41             24                 17  None   \n",
       "\n",
       "   temperature  top_p max_tokens  \n",
       "0          0.9    0.9       None  \n",
       "1          0.9    0.9       None  \n",
       "2          0.9    0.9       None  \n",
       "3          0.9    0.9       None  \n",
       "4          0.9    0.9       None  \n",
       "5          0.9    0.9       None  \n",
       "6          0.9    0.9       None  \n",
       "7          0.9    0.9       None  \n",
       "8          0.9    0.9       None  \n",
       "9          0.9    0.9       None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Async Chat Completions, limit to 2 concurrent API calls at any given time\n",
    "responses_list = await model.async_chat_completions(  # noqa: F704\n",
    "    messages_list=messages_list, num_concurrent=2, output_format=\"message_bundle_dict\"\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(responses_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated-llm-eval-BWtWBPiB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
