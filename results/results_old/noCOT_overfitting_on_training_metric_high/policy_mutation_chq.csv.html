<table><tr style='color: red;'><td>- Title: Summary comparison - correctness policy</td></tr><tr><td>?                              ^ ^^ ^^^^^
</td></tr><tr style='color: green;'><td>+ Title: Summary comparison - accuracy policy</td></tr><tr><td>?                             + ^^ ^ ^
</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr style='color: red;'><td>- Evaluate which summary includes less false information.</td></tr><tr style='color: green;'><td>+ Evaluate which summary includes less false information and accurately label the statements.</td></tr><tr><td>?                                                       ++++++++++++++++++++++++++++++++++++
</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr style='color: red;'><td>- You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information.</td></tr><tr style='color: green;'><td>+ You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements.</td></tr><tr><td>?                                                                                                                       ++++++++++++++++++++++++++++++++++++
</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr style='color: red;'><td>- A significantly better than B (Score: -2)</td></tr><tr style='color: green;'><td>+ A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>?                               +++++++++++++++++++++++
</td></tr><tr style='color: red;'><td>- A slightly better than B (Score: -1)</td></tr><tr style='color: green;'><td>+ A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>?                          +++++++++++++++++++++++
</td></tr><tr style='color: red;'><td>- Neither A or B is better than the other (Score: 0)</td></tr><tr style='color: green;'><td>+ Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>?                                         +++++++++++++++++++++++
</td></tr><tr style='color: red;'><td>- B slightly better than A (Score: 1)</td></tr><tr style='color: green;'><td>+ B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>?                          +++++++++++++++++++++++
</td></tr><tr style='color: red;'><td>- B significantly better than B (Score 2)</td></tr><tr><td>?                             ^
</td></tr><tr style='color: green;'><td>+ B significantly better than A and accurately labeled (Score 2)</td></tr><tr><td>?                             ^^^^^^^^^^^^^^^^^^^^^^^^
</td></tr><tr style='color: green;'><td>+ </td></tr><tr style='color: green;'><td>+ Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries.</td></tr></table><hr><table><tr style='color: red;'><td>- Title: Summary comparison - accuracy policy</td></tr><tr style='color: green;'><td>+ Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>?                                      ++++++++++++++
</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr style='color: red;'><td>- Evaluate which summary includes less false information and accurately label the statements.</td></tr><tr style='color: green;'><td>+ Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>?                                                                                           +++++++++++++++++++++++++++++++++++++++++
</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr style='color: red;'><td>- You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements.</td></tr><tr style='color: green;'><td>+ You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>?                                                                                                                                                           +++++++++++++++++++++++++++++++++++++++++
</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>  B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries.</td></tr><tr style='color: green;'><td>+ Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores.</td></tr></table><hr><table><tr><td>  Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr><td>  Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr style='color: red;'><td>- You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr style='color: green;'><td>+ You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>  B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr style='color: green;'><td>+ If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores.</td></tr><tr style='color: green;'><td>+ Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>?                                                                                                                                                                                                                              +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
</td></tr></table><hr><table><tr><td>  Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr><td>  Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr><td>  You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>  B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr style='color: red;'><td>- If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr style='color: green;'><td>+ Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr style='color: green;'><td>+ </td></tr><tr style='color: green;'><td>+ Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr></table><hr><table><tr><td>  Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr><td>  Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr><td>  You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>  B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr style='color: green;'><td>+ Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores.</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr style='color: green;'><td>+ Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the model has incorrectly labeled examples, it should reevaluate the content and context of the statements to ensure accurate labeling.</td></tr><tr><td>?                                                                                                                                                                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
</td></tr></table><hr><table><tr><td>  Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr><td>  Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr><td>  You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>  B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr><td>  </td></tr><tr><td>  Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores.</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the model has incorrectly labeled examples, it should reevaluate the content and context of the statements to ensure accurate labeling.</td></tr><tr style='color: green;'><td>+ Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the model has incorrectly labeled examples, it should reevaluate the content and context of the statements to ensure accurate labeling. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented.</td></tr><tr><td>?                                                                                                                                                                                                                                                                                                                                                                                                                                  ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
</td></tr></table><hr><table><tr><td>  Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr><td>  Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr><td>  You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>  B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr><td>  </td></tr><tr><td>  Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores.</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the model has incorrectly labeled examples, it should reevaluate the content and context of the statements to ensure accurate labeling. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented.</td></tr><tr style='color: green;'><td>+ Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the model has incorrectly labeled examples, it should reevaluate the content and context of the statements to ensure accurate labeling. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented. It should also consider the context and specific details of the original query to accurately label the statements.</td></tr><tr><td>?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
</td></tr></table><hr><table><tr><td>  Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr><td>  Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr><td>  You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>  B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr><td>  </td></tr><tr><td>  Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores.</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the model has incorrectly labeled examples, it should reevaluate the content and context of the statements to ensure accurate labeling. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented. It should also consider the context and specific details of the original query to accurately label the statements.</td></tr><tr style='color: green;'><td>+ Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the model has incorrectly labeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented. It should also consider the context and specific details of the original query to accurately label the statements. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented.</td></tr></table><hr><table><tr><td>  Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr><td>  Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr><td>  You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr><td>  B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr><td>  </td></tr><tr style='color: green;'><td>+ Note: The accuracy of the labeling should be prioritized, and the relevance of the information to the original query should also be considered when assigning scores. If the model has incorrectly labeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented. It should also consider the context and specific details of the original query to accurately label the statements. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented.</td></tr><tr style='color: red;'><td>- Note: Ensure that the accuracy of the labeling is prioritized in addition to evaluating the content of the summaries. The relevance of the information to the original query should also be considered when assigning scores.</td></tr><tr style='color: red;'><td>- </td></tr><tr style='color: red;'><td>- Note: The model should carefully consider the content of the summaries and ensure that the accuracy of the labeling is prioritized. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented. If the model has incorrectly labeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented. It should also consider the context and specific details of the original query to accurately label the statements. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented.</td></tr></table><hr><table><tr><td>  Title: Summary comparison - accuracy and relevance policy</td></tr><tr><td>  </td></tr><tr><td>  Objective</td></tr><tr><td>  Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query.</td></tr><tr><td>  </td></tr><tr><td>  Instructions</td></tr><tr><td>  You are given 2 summaries (A, B) created from a reference text. Evaluate which summary includes less false information and accurately label the statements based on relevance to the original query. If the summaries do not accurately represent the original query, provide a score based on the relevance and accuracy of the information presented.</td></tr><tr><td>  </td></tr><tr><td>  Scoring Criteria</td></tr><tr><td>  A significantly better than B and accurately labeled (Score: -2)</td></tr><tr><td>  A slightly better than B and accurately labeled (Score: -1)</td></tr><tr><td>  Neither A or B is better than the other and accurately labeled (Score: 0)</td></tr><tr style='color: red;'><td>- B slightly better than A and accurately labeled (Score: 1)</td></tr><tr><td>?                                                       -
</td></tr><tr style='color: green;'><td>+ B slightly better than A and accurately labeled (Score 1)</td></tr><tr><td>  B significantly better than A and accurately labeled (Score 2)</td></tr><tr><td>  </td></tr><tr style='color: red;'><td>- Note: The accuracy of the labeling should be prioritized, and the relevance of the information to the original query should also be considered when assigning scores. If the model has incorrectly labeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented. It should also consider the context and specific details of the original query to accurately label the statements. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented.</td></tr><tr style='color: green;'><td>+ Note: The accuracy of the labeling should be prioritized, and the relevance of the information to the original query should also be considered when assigning scores. If the model has incorrectly labeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented. It should also consider the context and specific details of the original query to accurately label the statements. If the model has previously mislabeled examples, it should reassess the summaries and provide the correct label based on the relevance and accuracy of the information presented. The model should carefully consider the specific details and context of the original query to ensure accurate labeling.</td></tr><tr><td>?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
</td></tr></table><hr>